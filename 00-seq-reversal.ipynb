{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import json, itertools\n",
    "torch.manual_seed(0)\n",
    "tqdm.get_lock().locks = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as a warm-up exercise let's confirm that quadratic-sized recurrent neural network is capable of reverting a simple sequence.\n",
    "Just for the sake of simplicity the sequence will be one-hot encoded and put through a network with 2 recurrent layers of $seq\\_length^2$ neurons and an output linear layer providing a final output with the next sequence item. \n",
    "\n",
    "TODO:\n",
    "- [ ] enable teacher forcing randomization\n",
    "- [ ] perform validation during the training procedure\n",
    "- [ ] improve the code quality\n",
    "- [ ] work in batches\n",
    "- [x] check border conditions\n",
    "- [ ] improve progress reporting\n",
    "- [x] try tensorboard output\n",
    "- [x] switch to DVC-based experimentation\n",
    "- [ ] implement sequence padding to enable variable sequence length capability in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 7, 5, 0, 3, 3, 3, 7, 1, 3],\n",
      "        [5, 2, 4, 7, 6, 0, 0, 4, 2, 1],\n",
      "        [6, 7, 7, 6, 0, 1, 5, 1, 5, 0],\n",
      "        [1, 4, 3, 0, 3, 5, 6, 7, 7, 0],\n",
      "        [2, 3, 0, 1, 3, 5, 3, 3, 6, 7],\n",
      "        [0, 1, 1, 1, 7, 0, 7, 2, 4, 7],\n",
      "        [3, 6, 3, 2, 7, 4, 2, 0, 0, 4],\n",
      "        [5, 5, 6, 0, 4, 1, 7, 4, 1, 2],\n",
      "        [2, 7, 0, 1, 1, 7, 1, 1, 3, 6],\n",
      "        [7, 3, 6, 2, 3, 0, 6, 3, 5, 4]])\n",
      "tensor([[3, 1, 7, 3, 3, 3, 0, 5, 7, 4],\n",
      "        [1, 2, 4, 0, 0, 6, 7, 4, 2, 5],\n",
      "        [0, 5, 1, 5, 1, 0, 6, 7, 7, 6],\n",
      "        [0, 7, 7, 6, 5, 3, 0, 3, 4, 1],\n",
      "        [7, 6, 3, 3, 5, 3, 1, 0, 3, 2],\n",
      "        [7, 4, 2, 7, 0, 7, 1, 1, 1, 0],\n",
      "        [4, 0, 0, 2, 4, 7, 2, 3, 6, 3],\n",
      "        [2, 1, 4, 7, 1, 4, 0, 6, 5, 5],\n",
      "        [6, 3, 1, 1, 7, 1, 1, 0, 7, 2],\n",
      "        [4, 5, 3, 6, 0, 3, 2, 6, 3, 7]])\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "with open(\"00-reversal-config.json\", 'r') as ch:\n",
    "    config = json.load(ch)\n",
    "\n",
    "src_sequences = torch.randint(config['VOCAB_SIZE'] - 2, [config['SAMPLES'], config['SEQ_LENGTH']])\n",
    "reversed_sequences = src_sequences.flip(1)\n",
    "print(src_sequences[:10])\n",
    "print(reversed_sequences[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sequences_one_hot = torch.zeros((config['SAMPLES'], config['SEQ_LENGTH'], config['VOCAB_SIZE'])).scatter(2, src_sequences.unsqueeze(2), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseEncoder(nn.Module):\n",
    "    def __init__(self, seq_length, vocab_size, rec_layers_count):\n",
    "        super(ReverseEncoder, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.rec_layers_count = rec_layers_count \n",
    "        self.rec_layers = nn.RNN(\n",
    "            input_size = vocab_size, \n",
    "            hidden_size = seq_length**2,\n",
    "            nonlinearity = \"tanh\",\n",
    "            num_layers = rec_layers_count,\n",
    "            batch_first = True\n",
    "        )\n",
    "        self.hidden_state = self.init_hidden_state()\n",
    "        \n",
    "    def init_hidden_state(self):\n",
    "        return torch.randn((self.rec_layers_count, 1, self.seq_length**2))\n",
    "        \n",
    "    def forward(self, input_sequence):\n",
    "        post_recurrent, hidden = self.rec_layers(input_sequence, self.hidden_state)\n",
    "\n",
    "        return post_recurrent, hidden\n",
    "    \n",
    "class ReverseDecoder(nn.Module):\n",
    "    def __init__(self, seq_length, vocab_size, rec_layers_count):\n",
    "        super(ReverseDecoder, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.rec_layers_count = rec_layers_count \n",
    "        self.rec_layers = nn.RNN(\n",
    "            input_size = vocab_size, \n",
    "            hidden_size = seq_length**2,\n",
    "            nonlinearity = \"tanh\",\n",
    "            num_layers = rec_layers_count,\n",
    "            batch_first = True\n",
    "        )\n",
    "        self.output = nn.Linear(seq_length*seq_length, vocab_size)\n",
    "        \n",
    "    def forward(self, input_sequence, hidden_state):\n",
    "        post_recurrent, hidden = self.rec_layers(input_sequence, hidden_state)\n",
    "        item_probs = F.log_softmax(self.output(post_recurrent), dim=2)\n",
    "        return item_probs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_model = ReverseEncoder(config['SEQ_LENGTH'], config['VOCAB_SIZE'], 2)\n",
    "dec_model = ReverseDecoder(config['SEQ_LENGTH'], config['VOCAB_SIZE'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReverseEncoder(\n",
      "  (rec_layers): RNN(10, 100, num_layers=2, batch_first=True)\n",
      ")\n",
      "ReverseDecoder(\n",
      "  (rec_layers): RNN(10, 100, num_layers=2, batch_first=True)\n",
      "  (output): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(enc_model)\n",
    "print(dec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(enc_model.parameters()) + list(dec_model.parameters()), \n",
    "    lr = config['LEARNING_RATE']\n",
    ")\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS = torch.tensor(config['VOCAB_SIZE'] - 2)\n",
    "EOS = torch.tensor(config['VOCAB_SIZE'] - 1)\n",
    "SOS_filler = torch.cat((torch.zeros(config['VOCAB_SIZE'] - 2), torch.tensor([1.0, 0.0])))\n",
    "EOS_filler = torch.cat((torch.zeros(config['VOCAB_SIZE'] - 1), torch.tensor([1.0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:04<00:00,  1.77it/s, epoch=1/15, mean_loss=1.55e+3, last_loss=1.26e+3]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.83it/s, epoch=2/15, mean_loss=1.49e+3, last_loss=1.22e+3]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s, epoch=3/15, mean_loss=1.4e+3, last_loss=1.13e+3] \n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s, epoch=4/15, mean_loss=1.34e+3, last_loss=1.1e+3] \n",
      "100%|██████████| 8/8 [00:04<00:00,  1.88it/s, epoch=5/15, mean_loss=1.31e+3, last_loss=1.08e+3]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s, epoch=6/15, mean_loss=1.29e+3, last_loss=1.07e+3]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s, epoch=7/15, mean_loss=1.27e+3, last_loss=1.06e+3]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s, epoch=8/15, mean_loss=1.27e+3, last_loss=1.08e+3]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s, epoch=9/15, mean_loss=1.29e+3, last_loss=1.03e+3]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.81it/s, epoch=10/15, mean_loss=1.26e+3, last_loss=1.03e+3]\n",
      "100%|██████████| 8/8 [00:04<00:00,  1.82it/s, epoch=11/15, mean_loss=1.21e+3, last_loss=991]    \n",
      "100%|██████████| 8/8 [00:04<00:00,  1.79it/s, epoch=12/15, mean_loss=1.18e+3, last_loss=980]    \n",
      "100%|██████████| 8/8 [00:04<00:00,  1.87it/s, epoch=13/15, mean_loss=1.14e+3, last_loss=945]    \n",
      "100%|██████████| 8/8 [00:04<00:00,  1.86it/s, epoch=14/15, mean_loss=1.1e+3, last_loss=917]     \n",
      "100%|██████████| 8/8 [00:04<00:00,  1.88it/s, epoch=15/15, mean_loss=1.06e+3, last_loss=886]    \n"
     ]
    }
   ],
   "source": [
    "losses = {}\n",
    "i = 0\n",
    "for epoch in range(config['EPOCHS']):\n",
    "    losses[epoch] = []\n",
    "    with tqdm(list(chunks(list(zip(src_sequences_one_hot, reversed_sequences)), config['BATCH_SIZE']))) as cit:\n",
    "        batch_element = 0\n",
    "        for chunk in cit:\n",
    "            loss = 0\n",
    "            for (sequence, sequence_y) in chunk:\n",
    "                X, y = sequence.unsqueeze(0), sequence_y\n",
    "                single_batch_result_out, hidden = enc_model(X)\n",
    "                Xss = torch.cat((SOS_filler.unsqueeze(0), X.squeeze(0)), dim=0)\n",
    "                yss = torch.cat((y, EOS.unsqueeze(0)), dim=0).unsqueeze(1)\n",
    "                for X_char, y_char in zip(Xss, yss):\n",
    "                    y_pred, hidden = dec_model(X_char.unsqueeze(0).unsqueeze(0), hidden)\n",
    "                    cur_loss = loss_function(y_pred.squeeze(0), y_char)\n",
    "                    loss += cur_loss\n",
    "                    i += 1\n",
    "            enc_model.zero_grad()\n",
    "            dec_model.zero_grad()\n",
    "            loss.backward()\n",
    "            losses[epoch].append(loss.tolist())\n",
    "            writer.add_scalar(\"loss\", loss.tolist(), global_step = epoch*config['BATCH_SIZE'] + batch_element)\n",
    "            writer.add_scalar(\"epoch\", epoch, global_step = epoch*config['BATCH_SIZE'] + batch_element)            \n",
    "            optimizer.step()\n",
    "            cit.set_postfix({\n",
    "                'epoch': f\"{epoch+1}/{config['EPOCHS']}\", \n",
    "                'mean_loss': sum(losses[epoch])/len(losses[epoch]),\n",
    "                'last_loss': losses[epoch][-1]\n",
    "            })\n",
    "            batch_element += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_sequence(seq, model):\n",
    "    seq_one_hot = torch.zeros((1, config['SEQ_LENGTH'], config['VOCAB_SIZE'])).scatter(2, seq.unsqueeze(2), 1.0)\n",
    "    (_, hidden) = model[0](seq_one_hot)\n",
    "    result = []\n",
    "    out, hidden = model[1](SOS_filler.unsqueeze(0).unsqueeze(0), hidden)\n",
    "    result.append(torch.argmax(out, dim=2).squeeze(0).squeeze(0).tolist())\n",
    "    for seq_char in seq_one_hot.squeeze(0):\n",
    "        out, hidden = model[1](seq_char.unsqueeze(0).unsqueeze(0), hidden)\n",
    "        result.append(torch.argmax(out, dim=2).squeeze(0).squeeze(0).tolist())\n",
    "    return result[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def const_generator(character_to_generate):\n",
    "    while True:\n",
    "        yield character_to_generate\n",
    "\n",
    "def up_stairs_generator(cap = config['VOCAB_SIZE'] - 2, cur_character=0):\n",
    "    while True:\n",
    "        cur_character += 1\n",
    "        if cur_character == cap + 1:\n",
    "            cur_character = 0\n",
    "        yield cur_character\n",
    "        \n",
    "def down_stairs_generator(cap = config['VOCAB_SIZE'] - 2, cur_character=0):\n",
    "    while True:\n",
    "        cur_character -= 1\n",
    "        if cur_character < 0:\n",
    "            cur_character = cap\n",
    "        yield cur_character\n",
    "        \n",
    "def two_way_stairs_generator(cap = config['VOCAB_SIZE'] - 2, cur_character=0):\n",
    "    delta = 1\n",
    "    while True:\n",
    "        cur_character += delta\n",
    "        if cur_character >= cap:\n",
    "            delta = -1\n",
    "            cur_character = cap\n",
    "        if cur_character <= 0:\n",
    "            delta = 1\n",
    "        yield cur_character\n",
    "\n",
    "\n",
    "\n",
    "test_cases = []\n",
    "for el in range(config['VOCAB_SIZE']):\n",
    "    test_cases.append(list(itertools.islice(const_generator(el), config['SEQ_LENGTH'])))\n",
    "    \n",
    "for el in range(config['VOCAB_SIZE']):\n",
    "    test_cases.append(list(itertools.islice(up_stairs_generator(el), config['SEQ_LENGTH'])))\n",
    "    \n",
    "for el in range(config['VOCAB_SIZE']):\n",
    "    test_cases.append(list(itertools.islice(down_stairs_generator(el), config['SEQ_LENGTH'])))\n",
    "        \n",
    "for el in range(config['VOCAB_SIZE']):\n",
    "    test_cases.append(list(itertools.islice(two_way_stairs_generator(el), config['SEQ_LENGTH'])))\n",
    "    \n",
    "for el in range(config['VOCAB_SIZE'] - 2, 0, -1):\n",
    "    test_cases.append(list(itertools.islice(two_way_stairs_generator(el, cur_character = el), config['SEQ_LENGTH'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-e49e5dbc5d66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdifflib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequenceMatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSequenceMatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreverse_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menc_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_cases\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-e49e5dbc5d66>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdifflib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequenceMatcher\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSequenceMatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreverse_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menc_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdec_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_cases\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "scores = ([SequenceMatcher(a = t[0].tolist(), b = reverse_sequence(t, (enc_model, dec_model))[::-1]).ratio() for t in test_cases])\n",
    "score = sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"00-seq-reversal-score.json\", 'r') as ch:\n",
    "    config = json.dump({\"score\": score}, ch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
