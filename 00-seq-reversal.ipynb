{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import json, itertools\n",
    "from datetime import datetime\n",
    "torch.manual_seed(0)\n",
    "tqdm.get_lock().locks = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as a warm-up exercise let's confirm that quadratic-sized recurrent neural network is capable of reverting a simple sequence.\n",
    "Just for the sake of simplicity the sequence will be one-hot encoded and put through a network with 2 recurrent layers of $seq\\_length^2$ neurons and an output linear layer providing a final output with the next sequence item. \n",
    "\n",
    "TODO:\n",
    "- [ ] enable teacher forcing randomization\n",
    "- [ ] perform validation during the training procedure\n",
    "- [ ] improve the code quality\n",
    "- [x] work in batches\n",
    "- [x] check border conditions\n",
    "- [ ] improve progress reporting\n",
    "- [x] try tensorboard output\n",
    "- [x] switch to DVC-based experimentation\n",
    "- [ ] implement sequence padding to enable variable sequence length capability in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 0, 2, 0, 1, 0, 1, 1, 1, 0],\n",
      "        [2, 2, 0, 0, 1, 2, 0, 0, 2, 0],\n",
      "        [2, 2, 2, 2, 2, 2, 1, 2, 0, 0],\n",
      "        [1, 0, 2, 0, 1, 0, 1, 2, 2, 1],\n",
      "        [2, 0, 1, 1, 1, 2, 1, 1, 2, 1],\n",
      "        [1, 2, 2, 1, 2, 2, 2, 1, 2, 2],\n",
      "        [1, 1, 0, 0, 1, 2, 1, 1, 2, 1],\n",
      "        [2, 2, 0, 1, 0, 2, 0, 1, 1, 2],\n",
      "        [2, 2, 2, 1, 0, 2, 1, 1, 1, 2],\n",
      "        [1, 1, 1, 1, 1, 2, 1, 1, 2, 1]])\n",
      "tensor([[0, 1, 1, 1, 0, 1, 0, 2, 0, 2],\n",
      "        [0, 2, 0, 0, 2, 1, 0, 0, 2, 2],\n",
      "        [0, 0, 2, 1, 2, 2, 2, 2, 2, 2],\n",
      "        [1, 2, 2, 1, 0, 1, 0, 2, 0, 1],\n",
      "        [1, 2, 1, 1, 2, 1, 1, 1, 0, 2],\n",
      "        [2, 2, 1, 2, 2, 2, 1, 2, 2, 1],\n",
      "        [1, 2, 1, 1, 2, 1, 0, 0, 1, 1],\n",
      "        [2, 1, 1, 0, 2, 0, 1, 0, 2, 2],\n",
      "        [2, 1, 1, 1, 2, 0, 1, 2, 2, 2],\n",
      "        [1, 2, 1, 1, 2, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "config = {}\n",
    "with open(\"00-reversal-config.json\", 'r') as ch:\n",
    "    config = json.load(ch)\n",
    "\n",
    "src_sequences = torch.randint(config['VOCAB_SIZE'] - 2, [config['SAMPLES'], config['SEQ_LENGTH']])\n",
    "reversed_sequences = src_sequences.flip(1)\n",
    "print(src_sequences[:10])\n",
    "print(reversed_sequences[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_sequences_one_hot = torch.zeros((config['SAMPLES'], config['SEQ_LENGTH'], config['VOCAB_SIZE'])).scatter(2, src_sequences.unsqueeze(2), 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseEncoder(nn.Module):\n",
    "    def __init__(self, seq_length, vocab_size, rec_layers_count):\n",
    "        super(ReverseEncoder, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.rec_layers_count = rec_layers_count \n",
    "        self.rec_layers = nn.RNN(\n",
    "            input_size = vocab_size, \n",
    "            hidden_size = seq_length**2,\n",
    "            nonlinearity = \"tanh\",\n",
    "            num_layers = rec_layers_count,\n",
    "            batch_first = True\n",
    "        )\n",
    "        \n",
    "    def init_hidden_state(self, input_sequence):\n",
    "        return torch.randn((self.rec_layers_count, input_sequence.size(0), self.seq_length**2))\n",
    "        \n",
    "    def forward(self, input_sequence):\n",
    "        post_recurrent, hidden = self.rec_layers(input_sequence, self.init_hidden_state(input_sequence))\n",
    "\n",
    "        return post_recurrent, hidden\n",
    "    \n",
    "class ReverseDecoder(nn.Module):\n",
    "    def __init__(self, seq_length, vocab_size, rec_layers_count):\n",
    "        super(ReverseDecoder, self).__init__()\n",
    "        self.seq_length = seq_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.rec_layers_count = rec_layers_count \n",
    "        self.rec_layers = nn.RNN(\n",
    "            input_size = vocab_size, \n",
    "            hidden_size = seq_length**2,\n",
    "            nonlinearity = \"tanh\",\n",
    "            num_layers = rec_layers_count,\n",
    "            batch_first = True\n",
    "        )\n",
    "        self.output = nn.Linear(seq_length*seq_length, vocab_size)\n",
    "        \n",
    "    def forward(self, input_sequence, hidden_state):\n",
    "        post_recurrent, hidden = self.rec_layers(input_sequence, hidden_state)\n",
    "        item_probs = F.log_softmax(self.output(post_recurrent), dim=2)\n",
    "        return item_probs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_model = ReverseEncoder(config['SEQ_LENGTH'], config['VOCAB_SIZE'], 2)\n",
    "dec_model = ReverseDecoder(config['SEQ_LENGTH'], config['VOCAB_SIZE'], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReverseEncoder(\n",
      "  (rec_layers): RNN(5, 100, num_layers=2, batch_first=True)\n",
      ")\n",
      "ReverseDecoder(\n",
      "  (rec_layers): RNN(5, 100, num_layers=2, batch_first=True)\n",
      "  (output): Linear(in_features=100, out_features=5, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(enc_model)\n",
    "print(dec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(enc_model.parameters()) + list(dec_model.parameters()), \n",
    "    lr = config['LEARNING_RATE']\n",
    ")\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS = torch.tensor(config['VOCAB_SIZE'] - 2)\n",
    "EOS = torch.tensor(config['VOCAB_SIZE'] - 1)\n",
    "SOS_filler = torch.cat((torch.zeros(config['VOCAB_SIZE'] - 2), torch.tensor([1.0, 0.0])))\n",
    "EOS_filler = torch.cat((torch.zeros(config['VOCAB_SIZE'] - 1), torch.tensor([1.0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 30.21it/s, epoch=1/35, mean_loss=12.7, last_loss=11.2]\n",
      "100%|██████████| 16/16 [00:00<00:00, 35.61it/s, epoch=2/35, mean_loss=11, last_loss=11]   \n",
      "100%|██████████| 16/16 [00:00<00:00, 43.78it/s, epoch=3/35, mean_loss=10.9, last_loss=10.7]\n",
      "100%|██████████| 16/16 [00:00<00:00, 41.44it/s, epoch=4/35, mean_loss=10.3, last_loss=9.78]\n",
      "100%|██████████| 16/16 [00:00<00:00, 25.98it/s, epoch=5/35, mean_loss=9, last_loss=7.87]   \n",
      "100%|██████████| 16/16 [00:00<00:00, 33.75it/s, epoch=6/35, mean_loss=6.84, last_loss=5.48]\n",
      "100%|██████████| 16/16 [00:00<00:00, 40.92it/s, epoch=7/35, mean_loss=4.05, last_loss=2.86]\n",
      "100%|██████████| 16/16 [00:00<00:00, 43.48it/s, epoch=8/35, mean_loss=1.64, last_loss=0.985]\n",
      "100%|██████████| 16/16 [00:00<00:00, 44.21it/s, epoch=9/35, mean_loss=0.562, last_loss=0.38] \n",
      "100%|██████████| 16/16 [00:00<00:00, 44.38it/s, epoch=10/35, mean_loss=0.254, last_loss=0.173]\n",
      "100%|██████████| 16/16 [00:00<00:00, 43.95it/s, epoch=11/35, mean_loss=0.152, last_loss=0.116]\n",
      "100%|██████████| 16/16 [00:00<00:00, 43.73it/s, epoch=12/35, mean_loss=0.102, last_loss=0.0887]\n",
      "100%|██████████| 16/16 [00:00<00:00, 43.82it/s, epoch=13/35, mean_loss=0.0791, last_loss=0.0714]\n",
      "100%|██████████| 16/16 [00:00<00:00, 41.45it/s, epoch=14/35, mean_loss=0.0649, last_loss=0.0554]\n",
      "100%|██████████| 16/16 [00:00<00:00, 43.82it/s, epoch=15/35, mean_loss=0.0541, last_loss=0.0499]\n",
      "100%|██████████| 16/16 [00:00<00:00, 43.93it/s, epoch=16/35, mean_loss=0.0463, last_loss=0.0441]\n",
      "100%|██████████| 16/16 [00:00<00:00, 43.77it/s, epoch=17/35, mean_loss=0.0406, last_loss=0.0366]\n",
      "100%|██████████| 16/16 [00:00<00:00, 43.57it/s, epoch=18/35, mean_loss=0.0358, last_loss=0.0332]\n",
      "100%|██████████| 16/16 [00:00<00:00, 43.00it/s, epoch=19/35, mean_loss=0.0319, last_loss=0.029] \n",
      "100%|██████████| 16/16 [00:00<00:00, 43.22it/s, epoch=20/35, mean_loss=0.0287, last_loss=0.0268]\n",
      "100%|██████████| 16/16 [00:00<00:00, 43.40it/s, epoch=21/35, mean_loss=0.0267, last_loss=0.0237]\n",
      "100%|██████████| 16/16 [00:00<00:00, 43.42it/s, epoch=22/35, mean_loss=0.0239, last_loss=0.0218]\n",
      "100%|██████████| 16/16 [00:00<00:00, 43.29it/s, epoch=23/35, mean_loss=0.022, last_loss=0.0199] \n",
      "100%|██████████| 16/16 [00:00<00:00, 43.22it/s, epoch=24/35, mean_loss=0.0202, last_loss=0.0186]\n",
      "100%|██████████| 16/16 [00:00<00:00, 43.17it/s, epoch=25/35, mean_loss=0.0186, last_loss=0.0168]\n",
      "100%|██████████| 16/16 [00:00<00:00, 28.24it/s, epoch=26/35, mean_loss=0.0174, last_loss=0.0164]\n",
      "100%|██████████| 16/16 [00:00<00:00, 29.47it/s, epoch=27/35, mean_loss=0.0161, last_loss=0.0146]\n",
      "100%|██████████| 16/16 [00:00<00:00, 40.44it/s, epoch=28/35, mean_loss=0.0153, last_loss=0.0143]\n",
      "100%|██████████| 16/16 [00:00<00:00, 36.86it/s, epoch=29/35, mean_loss=0.0142, last_loss=0.0134]\n",
      "100%|██████████| 16/16 [00:00<00:00, 41.47it/s, epoch=30/35, mean_loss=0.0132, last_loss=0.0121]\n",
      "100%|██████████| 16/16 [00:00<00:00, 41.56it/s, epoch=31/35, mean_loss=0.0126, last_loss=0.0116]\n",
      "100%|██████████| 16/16 [00:00<00:00, 41.82it/s, epoch=32/35, mean_loss=0.0119, last_loss=0.0111]\n",
      "100%|██████████| 16/16 [00:00<00:00, 40.80it/s, epoch=33/35, mean_loss=0.0112, last_loss=0.0105]\n",
      "100%|██████████| 16/16 [00:00<00:00, 41.72it/s, epoch=34/35, mean_loss=0.0105, last_loss=0.00964]\n",
      "100%|██████████| 16/16 [00:00<00:00, 40.72it/s, epoch=35/35, mean_loss=0.01, last_loss=0.00963]  \n"
     ]
    }
   ],
   "source": [
    "losses = {}\n",
    "tstart = datetime.now()\n",
    "for epoch in range(config['EPOCHS']):\n",
    "    losses[epoch] = []\n",
    "    chunked_X = chunks(src_sequences_one_hot, config['BATCH_SIZE'])\n",
    "    chunked_y = chunks(reversed_sequences, config['BATCH_SIZE'])\n",
    "    input_chunks = zip(chunked_X, chunked_y)\n",
    "    with tqdm(list(input_chunks)) as cit:\n",
    "        batch_element = 0\n",
    "        for chunk_X, chunk_y in cit:\n",
    "            loss = 0\n",
    "            y_eos = EOS.unsqueeze(0).repeat(chunk_y.size(0)).view(-1,1)\n",
    "            yss = torch.cat((chunk_y, y_eos), dim=1).unsqueeze(1)\n",
    "            x_sos = SOS_filler.unsqueeze(0).repeat(chunk_X.size(0), 1).unsqueeze(1)\n",
    "            single_batch_result_out, hidden = enc_model(chunk_X)\n",
    "            Xss = torch.cat((x_sos, chunk_X.squeeze(0)), dim=1)\n",
    "\n",
    "            for slice_id in range(chunk_y.size(1)):\n",
    "                y_pred, hidden = dec_model(Xss[:, slice_id].unsqueeze(1), hidden)\n",
    "                cur_loss = loss_function(y_pred.squeeze(1), yss[:, :, slice_id].squeeze(1))\n",
    "                loss += cur_loss\n",
    "            enc_model.zero_grad()\n",
    "            dec_model.zero_grad()\n",
    "            loss.backward()\n",
    "            losses[epoch].append(loss.tolist())\n",
    "            optimizer.step()\n",
    "            cit.set_postfix({\n",
    "                'epoch': f\"{epoch+1}/{config['EPOCHS']}\", \n",
    "                'mean_loss': sum(losses[epoch])/len(losses[epoch]),\n",
    "                'last_loss': losses[epoch][-1]\n",
    "            })\n",
    "\n",
    "tend = datetime.now()\n",
    "tdiff = tend - tstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_sequence(seq, model):\n",
    "    seq_one_hot = torch.zeros((1, config['SEQ_LENGTH'], config['VOCAB_SIZE'])).scatter(2, torch.tensor(seq).unsqueeze(0).unsqueeze(-1), 1.0)\n",
    "    (_, hidden) = model[0](seq_one_hot)\n",
    "    result = []\n",
    "    out, hidden = model[1](SOS_filler.unsqueeze(0).unsqueeze(0), hidden)\n",
    "    result.append(torch.argmax(out, dim=2).squeeze(0).squeeze(0).tolist())\n",
    "    for seq_char in seq_one_hot.squeeze(0):\n",
    "        out, hidden = model[1](seq_char.unsqueeze(0).unsqueeze(0), hidden)\n",
    "        result.append(torch.argmax(out, dim=2).squeeze(0).squeeze(0).tolist())\n",
    "    return result[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def const_generator(character_to_generate):\n",
    "    while True:\n",
    "        yield character_to_generate\n",
    "\n",
    "def up_stairs_generator(cap = config['VOCAB_SIZE'] - 2, cur_character=0):\n",
    "    while True:\n",
    "        cur_character += 1\n",
    "        if cur_character == cap + 1:\n",
    "            cur_character = 0\n",
    "        yield cur_character\n",
    "        \n",
    "def down_stairs_generator(cap = config['VOCAB_SIZE'] - 2, cur_character=0):\n",
    "    while True:\n",
    "        cur_character -= 1\n",
    "        if cur_character < 0:\n",
    "            cur_character = cap\n",
    "        yield cur_character\n",
    "        \n",
    "def two_way_stairs_generator(cap = config['VOCAB_SIZE'] - 2, cur_character=0):\n",
    "    delta = 1\n",
    "    while True:\n",
    "        cur_character += delta\n",
    "        if cur_character >= cap:\n",
    "            delta = -1\n",
    "            cur_character = cap\n",
    "        if cur_character <= 0:\n",
    "            delta = 1\n",
    "        yield cur_character\n",
    "\n",
    "\n",
    "\n",
    "test_cases = []\n",
    "for el in range(config['VOCAB_SIZE']):\n",
    "    test_cases.append(list(itertools.islice(const_generator(el), config['SEQ_LENGTH'])))\n",
    "    \n",
    "for el in range(config['VOCAB_SIZE']):\n",
    "    test_cases.append(list(itertools.islice(up_stairs_generator(el), config['SEQ_LENGTH'])))\n",
    "    \n",
    "for el in range(config['VOCAB_SIZE']):\n",
    "    test_cases.append(list(itertools.islice(down_stairs_generator(el), config['SEQ_LENGTH'])))\n",
    "        \n",
    "for el in range(config['VOCAB_SIZE']):\n",
    "    test_cases.append(list(itertools.islice(two_way_stairs_generator(el), config['SEQ_LENGTH'])))\n",
    "    \n",
    "for el in range(config['VOCAB_SIZE'] - 2, 0, -1):\n",
    "    test_cases.append(list(itertools.islice(two_way_stairs_generator(el, cur_character = el), config['SEQ_LENGTH'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "scores = ([SequenceMatcher(a = t, b = reverse_sequence(t, (enc_model, dec_model))[::-1]).ratio() for t in test_cases])\n",
    "score = sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./00-seq-reversal-score.json\", 'w') as ch:\n",
    "    config = json.dump({\"score\": score, \"training_time\": tdiff.total_seconds()}, ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
